model_params:
  num_boost_round: 1000
  early_stopping_rounds: 5
  model:
    type: xgboost
    # _target_: xgboost.XGBClassifier
    booster: gbtree
    device: cpu
    nthread: 1
    tree_method: hist
    objective: binary:logistic
  iterator:
    keep_data_in_memory: True
    binarize_task: True

hydra:
  sweeper:
    params:
      +model_params.model.eta: tag(log, interval(0.001, 1))
      +model_params.model.lambda: tag(log, interval(0.001, 1))
      +model_params.model.alpha: tag(log, interval(0.001, 1))
      +model_params.model.subsample: interval(0.5, 1)
      +model_params.model.min_child_weight: interval(1e-2, 100)
      model_params.num_boost_round: range(100, 1000)
      model_params.early_stopping_rounds: range(1, 10)
      +model_params.model.max_depth: range(2, 16)
      tabularization.min_code_inclusion_frequency: tag(log, range(10, 1000000))
