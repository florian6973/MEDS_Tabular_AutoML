# @package _global_

model_target:
  _target_: MEDS_tabular_automl.xgboost_model.XGBoostModel.initialize
  model_params: ${model_params}
  input_dir: ${input_dir}
  input_label_dir: ${input_label_dir}
  model_dir: ${model_dir}
  output_filepath: ${output_filepath}
  log_dir: ${log_dir}
  cache_dir: ${cache_dir}
  imputer: ${model_params.iterator.imputer}
  normalization: ${model_params.iterator.normalization}
  # tabularization: ${tabularization} # Ideally we should define tabularization here, but there is an issue initializing with it's resolvers.

model_params:
  num_boost_round: 1000
  early_stopping_rounds: 5
  model:
    booster: gbtree
    device: cpu
    nthread: 1
    tree_method: hist
    objective: binary:logistic
  iterator:
    keep_data_in_memory: True
    binarize_task: True
    normalization: ${normalization}
    imputer: ${imputer}

hydra:
  sweeper:
    direction: maximize
    n_trials: 250
    n_jobs: 25

    params:
      +model_params.model.eta: tag(log, interval(0.001, 1))
      +model_params.model.lambda: tag(log, interval(0.001, 1))
      +model_params.model.alpha: tag(log, interval(0.001, 1))
      +model_params.model.subsample: interval(0.5, 1)
      +model_params.model.min_child_weight: interval(1e-2, 100)
      model_params.num_boost_round: range(100, 1000)
      model_params.early_stopping_rounds: range(1, 10)
      +model_params.model.max_depth: range(2, 16)
      tabularization.min_code_inclusion_frequency: tag(log, range(10, 1000000))
