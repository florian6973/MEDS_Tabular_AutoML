# @package _global_

model_target:
  _target_: MEDS_tabular_automl.sklearn_model.SklearnModel.initialize
  model_params: ${model_params}
  input_dir: ${input_dir}
  input_label_dir: ${input_label_dir}
  model_dir: ${model_saving.model_dir}
  model_file_stem: ${model_saving.model_file_stem}
  model_file_extension: ${model_saving.model_file_extension}
  log_dir: ${log_dir}
  cache_dir: ${cache_dir}
  imputer: ${model_params.iterator.imputer}
  normalization: ${model_params.iterator.normalization}

model_params:
  epochs: 20
  early_stopping_rounds: 5
  model:
    _target_: sklearn.linear_model.LogisticRegression
    penalty: "l2"
    dual: false
    tol: 0.0001
    C: 1.0
    fit_intercept: True
    intercept_scaling: 1
    class_weight: null
    random_state: null
    solver: "lbfgs"
    max_iter: 100

  iterator:
    keep_data_in_memory: True
    binarize_task: True
    normalization: ${normalization}
    imputer: ${imputer}

hydra:
  sweeper:
    direction: maximize
    n_trials: 250
    n_jobs: 25

    params:
      model_params.model.C: tag(log, interval(1e-6, 1))
      model_params.model.penalty: choice(['l1', 'l2', 'elasticnet'])
      model_params.model.solver: choice(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])
      model_params.epochs: range(10, 100)
      model_params.early_stopping_rounds: range(1, 10)
